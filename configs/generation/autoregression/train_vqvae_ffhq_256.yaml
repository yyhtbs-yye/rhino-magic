_import: configs/base/train_base.yaml

boat:
  _target_: 'rhino.boats.autoregression.codebook_autoregression_boat.CodebookAutoregressionBoat'

  models:
    net:
      path: 'rhino.nn.autoregression.pixelcnn.pixelcnn'
      name: 'PixelCNN'
      params:
        vocab_size: $vocab_size
        kernel_size: $kernel_size
        in_channels: $in_channels
        hidden_channels: $hidden_channels
  
    latent_encoder:
      path: 'rhino.nn.wrappers.autoencoder_kl_wrapper'   # Path to import the model class
      name: 'AutoencoderKLWrapper'              # Name of the model class to use
      pretrained: 'stabilityai/sd-vae-ft-mse'  # Example: A common pretrained VAE from Stable Diffusion

    vector_quantizer:
      path: 'rhino.nn.vector_quantization.pixel_vector_quantizer'
      name: 'PixelVectorQuantizer'
      params:
        num_codes: $vocab_size
        dim: 4
        eps: 1e-5
        pretrained: 'pretrained/pixel_vq_model_d4k_ffhq256.pt'
    
  losses: 
    net:
      path: 'rhino.nn.losses.wrappers.pixel_loss'
      name: 'PixelLoss'
      params: 
        base_loss_fn_str: ce

optimization: 
  net:
    path: 'torch.optim'
    name: 'Adam'
    params:
      lr: 0.0001
      betas: [0.9, 0.999]
      weight_decay: 0.0
    lr_scheduler: {}
    
  use_ema:
    ema_decay: 0.999
    ema_start: $ema_start

logging:
  root_dir: 'work_dirs'
  name: $experiment_name
  loggers:
    tensorboard:
      path: 'trainer.loggers.tensorboard'
      name: 'TensorBoardLogger'
      params:
        log_dir: 'work_dirs'
        name: $experiment_name

trainer: 
  devices: $devices
  max_epochs: 400
  val_check_epochs: 1
  state_save_epochs: 1
  visualization:
    save_images: true
    wnb: [0.5, 0.5]  # for visualization

validation: 
  save_images: true
  num_vis_samples: 4
  use_reference: true
  target_metric_name: 'dummy_metric'
  metrics:
    dummy_metric:
      path: 'rhino.metrics.dummy_metric'
      name: 'DummyMetric'
      params: {}

# Data configuration
data:
  path: trainer.data_modules.image_data_module
  name: DistTrainDistValidDataModule
  config: 
    train_dataloader:
      dataset:
        path: 'trainer.torch_datasets.basic_image_dataset'
        name: 'BasicImageDataset'         # Name of the model class to use
        params:
          # max_dataset_size: 256
          folder_paths: $train_folder_paths
          data_prefix:
            gt: ''
          pipeline:
            - type: LoadImageFromFile
              keys: [gt]
            - type: Normalize
              keys: [gt]
              mean: [0.5, 0.5, 0.5]
              std: [0.5, 0.5, 0.5]
      batch_size: $train_batch_size
      num_workers: $num_workers
      pin_memory: false
      persistent_workers: false
      sampler:
        type: DefaultSampler
        shuffle: true

    # Validation dataloader configuration
    valid_dataloader:
      dataset:
        path: 'trainer.torch_datasets.basic_image_dataset'           # Path to import the model class
        name: 'BasicImageDataset'         # Name of the model class to use
        params:
          max_dataset_size: 32
          folder_paths: $valid_folder_paths
          data_prefix:
            gt: ''
          pipeline:
            - type: LoadImageFromFile
              keys: [gt]
            - type: Normalize
              keys: [gt]
              mean: [0.5, 0.5, 0.5]
              std: [0.5, 0.5, 0.5]
      batch_size: $valid_batch_size
      num_workers: $num_workers
      pin_memory: false
      persistent_workers: false
      sampler:
        type: DefaultSampler
        shuffle: true


callbacks: 
  - path: trainer.callbacks.state_cleaner
    name: KeepTopKStateCallback
    params:
      top_k: 5

_vars:

  devices: [0, 1, 2, 3]  # Example for 4 GPUs; use [0] for single GPU or [] for CPU

  train_batch_size: 64
  valid_batch_size: 8
  num_workers: 16

  vocab_size: 4096
  in_channels: 1
  kernel_size: 9
  hidden_channels: 240

  train_folder_paths:
    gt: data/ffhq/ffhq_imgs/ffhq_256
    
  valid_folder_paths:
    gt: data/celeba/subsets/celeba_256

  experiment_name: vqvae_ffhq_256

  ema_start: 0