_import: configs/base/train_base_sr3.yaml

boat:
  path: 'rhino.diffusers.boats.conditioned.latent_diffusing'
  name: 'ConditionedLatentDiffusionBoat'            

  encoder:
    path: 'rhino.autoencoders.networks.autoencoder_wrappers' 
    name: 'AutoencoderKLWrapper'
    pretrained: 'stabilityai/sd-vae-ft-mse'

  context_encoder:
    path: torch.nn
    name: PixelUnshuffle
    params: 
      downscale_factor: 2   # 64 -> 32

_vars:

  device: 'cuda:3'

  sample_channels: 4
  condition_channels: 12    # 3 * 2 * 2 (downscale_factor: 2)
  out_channels: 4
  sample_size: [256, 256]
  batch_size: 128

  train_folder_paths:
    gt: data/ffhq/ffhq_imgs/ffhq_256
    lq: data/ffhq/ffhq_imgs/ffhq_64
    
  valid_folder_paths:
    gt: data/celeba/subsets/celeba_256
    lq: data/celeba/subsets/celeba_64

  experiment_name: sr3_unet_ldm_ffhq_64_256

  ema_start: 0