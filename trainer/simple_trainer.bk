import torch
from pathlib import Path
from datetime import datetime
from tqdm import tqdm

from trainer.debuggers.memory_snapshot import MemorySnapshot, analyze_leaking_type

class Trainer:
    def __init__(
        self, boat, trainer_config, 
        callbacks=None, logger=None,
        run_folder=None, resume_from=None,
    ):
        self.max_epochs = trainer_config.get('max_epochs', 10)
        self.device = torch.device(trainer_config.get('device', 'cpu'))
        self.callbacks = callbacks or []
        self.val_check_steps = trainer_config.get('val_check_steps', None)
        self.val_check_epochs = trainer_config.get('val_check_epochs', None)
        self.state_save_steps = trainer_config.get('state_save_steps', None)
        self.state_save_epochs = trainer_config.get('state_save_epochs', None)
        self.save_images = trainer_config.get('save_images', False)
        self.logger = logger
        
        boat.configure_optimizers()
        boat.configure_losses()
        boat.configure_metrics()

        if resume_from:
            self.resume_from = Path(resume_from) if isinstance(resume_from, str) else resume_from
            self.run_folder = Path(run_folder) if isinstance(run_folder, str) else run_folder
            self.boat, metadata = boat.load_state(self.resume_from)
            self.global_step = metadata.get('global_step', 0)
            self.start_epoch = metadata.get('epoch', 0)
        else:
            self.resume_from = None
            self.run_folder = Path(run_folder) if isinstance(run_folder, str) else run_folder
            self.global_step = 0
            self.start_epoch = 0
            self.boat = boat

        # Attach the trainer to the boat
        self.boat.attach_trainer(self)

        self.valid_step_records = {}
        self.valid_epoch_records = {}


    def fit(self, data_module, memory_debug=True):

        # Initialize memory tracker
        memory_tracker = MemorySnapshot()

        self.boat.to(self.device)

        for epoch in range(self.start_epoch, self.max_epochs):

            self.boat.train()
            
            total_batches = len(data_module.train) if hasattr(data_module.train, '__len__') else None

            if memory_debug:
                epoch_snapshot = memory_tracker.take_snapshot(f"Epoch {epoch}, start")
                # Compare current start with previous end snapshot if it exists
                if 'prev_end_snapshot' in locals():
                    print("\n==== Memory tracking details (prev end to current start) ====")
                    type_diffs = memory_tracker.compare_snapshots(prev_end_snapshot, epoch_snapshot)
                    
                    leaking_types = [t for t, _, _, d in type_diffs if d > 100]  # Types with 100+ increase
                    if leaking_types:
                        print("\nDetailed analysis of leaking types:")
                        for leak_type in leaking_types[:3]:  # Analyze top 3 leakers
                            analyze_leaking_type(leak_type)

            for batch_idx, batch in tqdm(enumerate(data_module.train),
                                         total=total_batches,
                                         desc=f"Epoch {epoch}  |  {datetime.now():%Y-%m-%d %H:%M:%S}",
                                         unit="batch"):

                if batch_idx == 0 and epoch == self.start_epoch and self.resume_from:
                    self.global_step -= 1  # Adjust for resuming
                self.global_step += 1

                batch = self._move_batch_to_device(batch)

                loss = self.boat.training_step(batch, batch_idx)

            if memory_debug:
                current_end_snapshot = memory_tracker.take_snapshot(f"Epoch {epoch}, end")
                # Compare current end with current start
                print("\n==== Memory tracking details (current start to current end) ====")
                type_diffs = memory_tracker.compare_snapshots(epoch_snapshot, current_end_snapshot)
                
                leaking_types = [t for t, _, _, d in type_diffs if d > 100]  # Types with 100+ increase
                if leaking_types:
                    print("\nDetailed analysis of leaking types:")
                    for leak_type in leaking_types[:3]:  # Analyze top 3 leakers
                        analyze_leaking_type(leak_type)
                prev_end_snapshot = current_end_snapshot
            
            self.boat.lr_scheduling_step() 

            self.logger.flush()

            if data_module.valid is not None:
                if self.val_check_epochs is not None and epoch % self.val_check_epochs == 0:
                    avg_loss = self._run_validation(data_module.valid, None, epoch)
                    self.valid_epoch_records[epoch] = {'avg_loss': avg_loss}

            if self.state_save_epochs is not None and epoch % self.state_save_epochs == 0:
                state_path = self.boat.save_state(self.run_folder, 'boat_state', global_step=self.global_step, epoch=epoch+1)
                
                if epoch not in self.valid_epoch_records:
                    self.valid_epoch_records[epoch] = {}
                self.valid_epoch_records[epoch]['state_path'] = state_path

    def _run_validation(self, val_dataloader, global_step=None, epoch=None):
        for cb in self.callbacks:
            cb.on_validation_start(self, self.boat)
        
        step_losses = []

        self.boat.eval()

        with torch.no_grad():
            for batch_idx, batch in enumerate(val_dataloader):
                batch = self._move_batch_to_device(batch)
                loss = self.boat.validation_step(batch, batch_idx)
                for cb in self.callbacks:
                    cb.on_validation_batch_end(self, self.boat, batch, batch_idx, outputs=loss)
                step_losses.append(loss)
        
        if len(step_losses) == 0:
            raise ValueError("Validation step returned no losses. Check your validation step implementation.")
        avg_loss = sum(step_losses) / len(step_losses)

        for cb in self.callbacks:
            cb.on_validation_end(self, self.boat)

        return avg_loss

    def _move_batch_to_device(self, batch):
        if isinstance(batch, (list, tuple)):
            return [self._move_batch_to_device(x) for x in batch]
        elif isinstance(batch, dict):
            return {k: self._move_batch_to_device(v) for k, v in batch.items()}
        elif hasattr(batch, 'to'):
            return batch.to(self.device)
        else:
            return batch
